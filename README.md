# Reinforcement Learning meets Music Theory: A Music-Driven Framework for melody harmonization

## Theoretical background (animations)

Animations realized using [Manim](https://www.manim.community/), whose code can be found [Here](https://github.com/pietrobegotti/msdegree_presentation)

## State space

<video src = "https://github.com/pietrobegotti/harmonization/main/animations/state_space.mp4"></video>

### Model

<video src = "https://github.com/pietrobegotti/harmonization/main/animations/model.mp4"></video>

### Working example

<video src = "https://github.com/pietrobegotti/harmonization/main/animations/working_implementation.mp4"></video>


## Package

A Reinforcement Learning package to generate musical harmonies, starting from a general sequence of notes in the scale of C major. Outputs musical harmonies, MIDI files, and mp4 videos.

### Prerequisites

- **ffmpeg** must be installed on your system.
  - [Download ffmpeg](https://ffmpeg.org/download.html)
  

### Examples

Here are a few example outputs generated by the package. The top line is the melody, given as input. The other notes played are generated. 
In this cases the melody is invented and borrowed from the famous Ode to joy from Ludwig van Beethoven.

<video src = "https://github.com/pietrobegotti/harmonization/main/examples/Sequence_#1.mp4"></video>
<video src = "https://github.com/pietrobegotti/harmonization/main/examples/Sequence_#2.mp4"></video>


<!-- https://github.com/user-attachments/assets/e7a52a7e-48b0-4076-8552-e5e392ad850d
https://github.com/user-attachments/assets/9b4d98df-2e92-45ec-9ef5-695c0d947d09 -->

https://github.com/user-attachments/assets/cbf6e990-24db-4dea-8d9b-5043ece592c2


https://github.com/user-attachments/assets/1b843689-b5b2-4dd0-9749-84a2180ce0f3



### Installation

Install this package via `pyPI`: 

```bash
pip install harmonization-env
```

https://pypi.org/project/harmonization-env/

### Basic Usage

Here's a complete example showing the main features:

```python

import torch
from harmonization_env_package import *

path_to_params = "..."
env = HarmonizationEnv(device = 'cpu')

net = NetM.load_from_checkpoint(path_to_params, device = 'cpu')

# Create a melody sequence
# Notes are represented as MIDI numbers (60 = middle C)
melody = torch.tensor([64, 64, 65, 65, 
                       67, 69, 69, 62,
                       67, 67, 68, 71,
                       69, 71, 72, 65,
                       64, 64, 62, 62,
                       60, 60, 60, 60,
                       60], dtype = torch.int32)

melody += 12


# get output
chords, reward = agent.get(
    melody = melody,
)

run = chords[0, :]


v = Voicer(melody, run)
voices = v.get()

player = MIDIGenerator(tempo = 80) 

# get and play midi output
player.generate(voices, filenames = 'test0.mid')
player.play(filename = 'test0.mid')

# Create visualization video
# Download soundfont from https://member.keymusician.com/Member/FluidR3_GM/index.html
vg = VideoGenerator('test0.mid', soundfont_path='FluidR3_GM.sf2')
vg.get_video(output_filename='output.mp4')

```




